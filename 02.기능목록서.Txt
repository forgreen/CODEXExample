SplitDataModule 상세 기능목록서

1) #B7D12-F0001: 데이터 분할 설정 (학습/검증/테스트 비율)
기능 개요:
데이터셋을 학습용, 검증용, 테스트용으로 사용자 지정 비율에 따라 분할하는 기능이다. 사용자는 전체 데이터 중 몇 퍼센트를 학습에 사용할지, 검증과 테스트에 각각 얼마나 할당할지 결정할 수 있다. 이 기능은 주어진 비율대로 데이터 레코드를 무작위로 할당하여 각 용도별 하위 집합을 생성하며, 모델 학습과 평가를 위한 기본적인 데이터셋 분리를 수행한다. 기본적으로 데이터 순서는 섞어(shuffle) 무작위 분포를 보장하며, 재현성을 위해 시드 값을 설정할 수 있다. 입력 파라미터 및 유효성 조건:
dataset: 분할할 원본 데이터셋 (예: 레코드의 리스트, 테이블 또는 DataFrame 형태). 비어 있지 않은 유효한 데이터셋이어야 한다.
train_fraction (float): 학습용 데이터 비율 (0 < train_fraction < 1). 필수 값이며, 분할 후 전체 데이터 중 이 비율만큼을 학습 세트로 할당한다.
validation_fraction (float, 선택): 검증용 데이터 비율 (0 ≤ validation_fraction < 1). 기본값 0 (사용하지 않음)으로 둘 수 있으며, 0보다 큰 값으로 지정하면 해당 비율만큼을 검증 세트로 할당한다.
test_fraction (float): 테스트용 데이터 비율 (0 ≤ test_fraction < 1). 기본값은 0으로, 검증 세트를 사용하지 않는 경우에는 테스트 비율을 명시적으로 지정해야 한다.
shuffle (bool): 분할 전에 데이터셋을 무작위로 섞을지 여부. 기본값 True이며, False로 설정하면 데이터 순서를 유지한 채 순차적으로 분할한다.
random_seed (int, 선택): 셔플 시드를 지정하여 분할 결과를 재현 가능하게 한다. 지정하지 않으면 시스템 기본 시드를 사용하며, 동일한 시드와 데이터셋에 대해서는 항상 동일하게 분할된다.
유효성 조건: train_fraction + validation_fraction + test_fraction == 1.0 이어야 한다(일부 비율이 0인 경우 해당 부분을 제외하고 나머지가 1이 되도록 설정). 모든 fraction 값은 0 이상 1 이하의 실수여야 하며, 음수이거나 1을 초과해서는 안 된다. 또한 fraction 값이 0이 아닌 분할에는 최소 1개 이상의 데이터 레코드가 할당될 수 있는 충분한 데이터셋 크기가 필요하다. 예를 들어, 데이터셋 크기가 매우 작아서 지정된 비율대로 분할 시 일부 분할에 0개 샘플이 될 경우 오류 또는 경고를 발생시킨다. 내부 처리 흐름 및 로직 요약:
입력 검증: 제공된 dataset이 비어있는지 확인하고, 분할 비율(train_fraction, validation_fraction, test_fraction)의 합이 유효한지 체크한다. 합이 1이 아닐 경우 또는 비율 값이 범위를 벗어나면 예외를 발생시킨다. 또한 데이터셋 크기에 비해 분할 비율로 요구되는 샘플 수가 너무 작은지 확인한다 (예: 데이터셋 크기 5에서 테스트 비율 0.5인 경우 테스트에 2.5개 → 2개 할당, 나머지 3개 학습에 할당 식으로 조정됨).
데이터 섞기: shuffle=True인 경우 주어진 random_seed를 사용하여 데이터셋의 레코드 순서를 무작위로 섞는다. shuffle=False인 경우 원본 입력 순서를 유지한다.
분할 크기 계산: 전체 레코드 수 N을 기준으로 각 세트에 할당할 개수를 계산한다. 예를 들어, train_count = floor(train_fraction * N), validation_count = floor(validation_fraction * N)로 설정하고, test_count = N - train_count - validation_count로 나머지를 할당한다. (필요시 반올림 또는 내림을 사용하여 정수로 만들며, 합계가 정확히 N이 되도록 마지막 분할에 남은 데이터를 모두 포함시킨다.) 검증 비율이 0인 경우에는 validation_count = 0으로 간주하고 테스트에 나머지를 할당한다. 마찬가지로 테스트 비율이 0이면 테스트 분할 없이 학습과 검증만 계산한다.
데이터 슬라이싱: 섞인 데이터셋(또는 원본 데이터셋)을 앞에서부터 계산된 train_count만큼 잘라 학습 세트를 구성한다. 다음 validation_count만큼을 검증 세트로 할당한다(만약 검증 비율이 0이면 이 단계 생략). 그리고 나머지 test_count 레코드를 테스트 세트로 사용한다. 이때 각 레코드들은 하나의 세트에만 속하도록 분할하며, 어떤 두 세트 간에도 중복이 없다.
출력 생성: 세 개(또는 두 개)의 분할 세트를 담은 구조를 생성한다. 예를 들어 {"train": train_set, "validation": val_set, "test": test_set} 형태의 딕셔너리를 준비하거나, 각각의 세트를 명시적으로 반환한다. 각 세트(train_set, val_set, test_set)는 입력 데이터셋과 동일한 형식(예: 동일한 칼럼 구조의 테이블, 리스트 등)으로 구성된다.
완료 및 반환: 학습/검증/테스트 세트의 크기 및 분포를 로그로 남길 수 있으며(예: 각 세트에 포함된 레코드 수), 최종 분할 결과를 반환한다.
출력 데이터의 구조 및 설명:
분할된 데이터셋들을 포함하는 자료구조를 반환한다. 대표적으로 키로 구분된 딕셔너리 구조를 사용하며:
"train": 학습용 데이터셋 (예: 레코드 리스트 혹은 DataFrame). train_fraction에 대응하는 수의 레코드를 포함한다.
"validation": 검증용 데이터셋. validation_fraction이 0이 아닌 경우에만 포함되며, 해당 비율만큼의 레코드를 가진다. (검증 비율을 사용하지 않았다면 이 키는 없거나 빈 값으로 둘 수 있다.)
"test": 테스트용 데이터셋. test_fraction에 대응하는 레코드들을 포함한다 (테스트 비율 0인 경우 생략 가능).
각 세트의 데이터 구조는 원본 dataset과 동일하며, 레코드의 속성(칼럼) 구조도 동일하게 유지된다. 데이터셋이 무작위로 섞여 분할된 경우 각 세트는 원본 분포를 무작위 샘플링한 부분집합이다. 만약 shuffle=False로 순차 분할한 경우, "train"은 원본 데이터의 앞부분, "test"는 뒷부분의 연속된 구간 데이터를 가지게 된다. 이 출력 결과는 모델 학습 단계에 학습 세트를 공급하고, 검증 세트를 모델 튜닝에, 테스트 세트를 최종 성능 평가에 사용하는 등 용도에 맞게 활용된다. 발생 가능한 예외 또는 경고 조건:
잘못된 비율 합계 오류: train_fraction, validation_fraction, test_fraction 값의 합이 1.0이 아닌 경우 예외를 발생시킨다. 예를 들어 train=0.7, val=0.2, test=0.1이 아닌 train=0.7, val=0.3, test=0.2 (합 1.2)처럼 합이 1을 넘거나 부족하면 분할 비율이 모순되므로 오류를 반환한다.
분할 비율 범위 오류: fraction 값들이 0 미만이거나 1 초과인 경우 예외를 발생시킨다. 비율 값은 유효한 확률 값(0~1)이어야 한다.
데이터셋 크기 부족 경고/오류: 데이터셋이 지나치게 작아 지정된 분할을 적용할 수 없는 경우 예외 또는 경고가 발생한다. 예를 들어, 2개의 레코드만 있는 데이터셋에 train_fraction=0.5, val_fraction=0.25, test_fraction=0.25로 3-way 분할을 요구하면, 각 분할에 최소 0.5, 0.25, 0.25개의 레코드에 해당하여 검증/테스트 세트가 빈 상태가 될 수 있다. 이러한 경우 **"데이터셋 크기가 분할 비율에 비해 부족합니다"**와 같은 오류를 내거나, 일부 세트는 빈 세트로 반환하면서 경고를 기록할 수 있다.
빈 데이터셋 오류: 입력 dataset이 비어 있을 경우 분할을 수행할 수 없으므로 즉시 예외를 일으킨다. (예: **"분할할 데이터가 없습니다"**와 같은 메시지)
기타: 분할 과정에서 예상치 못한 문제가 발생하면 (예: 데이터 타입 불일치 등) 일반적인 예외 처리 규칙에 따라 오류를 보고한다. 또한 shuffle=False로 설정한 경우, 데이터가 시간순으로 이미 정렬되어 있지 않다면 결과가 편향될 수 있다는 점을 로그나 경고로 알릴 수 있다 (예: "경고: shuffle=False 설정으로 인해 데이터 원본 순서대로 분할됩니다. 데이터 순서에 특정 패턴이 있는 경우 모델 평가가 왜곡될 수 있습니다.").
예시 시나리오:
예를 들어, 1,000개의 샘플로 이루어진 데이터셋이 있다고 가정한다. 사용자가 학습:검증:테스트 비율을 **8:1:1 (즉, 0.8, 0.1, 0.1)**로 설정하고 shuffle=True, random_seed=42로 호출하면, 함수는 내부적으로 데이터셋을 무작위로 섞은 뒤 약 800개의 레코드를 학습용으로, 100개를 검증용으로, 100개를 테스트용으로 할당한다. 이 때 각 세트는 원본 데이터의 무작위 샘플이며 중복이 없다. 결과 출력은 train 키에 800개 레코드, validation 키에 100개, test 키에 100개 레코드가 담긴 딕셔너리로 반환된다. 사용자는 반환된 학습 세트를 모델 학습에 투입하고, 검증 세트로 모델 성능을 중간 평가하며, 최종적으로 테스트 세트로 모델의 일반화 성능을 확인하게 된다. 만약 검증 세트를 사용하지 않고 학습/테스트만 8:2로 분할하고 싶다면 validation_fraction=0으로 두고 train_fraction=0.8, test_fraction=0.2로 호출하면 된다. 그러면 전체 1,000개 중 800개는 학습, 200개는 테스트로 분리되며, 검증 세트는 생성되지 않는다.

2) #B7D12-F0002: 계층적 데이터 분할 (라벨 분포 유지)
기능 개요:
주어진 레이블(label) 또는 카테고리 분포를 유지하며 데이터셋을 분할하는 기능이다. 분류 문제 등의 불균형 데이터셋에서 각 클래스 비율이 학습/검증/테스트 세트에 골고루 반영되도록 데이터를 나누어준다. 기본 분할 기능(#B7D12-F0001)을 확장한 것으로, 무작위 샘플링 대신 **계층적 샘플링(stratified sampling)**을 수행하여 각 분할 세트의 레이블 분포가 원본 데이터셋의 분포와 최대한 일치하도록 보장한다. 이를 통해 모델 학습/평가 시 레어 클래스 손실이나 분포 편향을 줄이고, 각 세트에서 모든 레이블에 대한 평가가 가능하도록 한다. 입력 파라미터 및 유효성 조건:
dataset: 분할할 원본 데이터셋 (표 형태의 데이터나 레코드 리스트 등).
label_field: 레이블로 사용할 속성 또는 값. 예를 들어 데이터셋이 표 형태일 경우 레이블이 들어있는 칼럼 이름을 지정할 수 있고, 또는 별도로 레이블 목록(labels)을 전달할 수도 있다. 이 값은 전체 데이터셋의 각 레코드에 대해 해당 레코드가 속하는 클래스/그룹을 나타내야 한다.
train_fraction, validation_fraction, test_fraction: 각 세트로 분할할 비율. 사용법과 제한 조건은 #B7D12-F0001의 fraction 파라미터들과 동일하다 (합이 1.0이어야 하며, 일부 0 값 허용 등).
shuffle (bool): 기본값 True. 계층적 분할의 경우에도 shuffle=True면 각 레이블 그룹 내부에서 무작위 추출을 한다. 만약 False인 경우, 레이블 순서를 유지한 채 분할하지만 일반적으로 계층적 분할에서는 True로 두는 것이 권장된다 (레이블 순서를 유지하면 분할 간 편차가 생길 수 있음).
random_seed (int, 선택): 무작위 추출시 사용할 시드. 동일 시드 사용 시 계층 샘플링된 분할 결과도 재현 가능하다.
유효성 조건: dataset 내에 label_field로 지정한 값이 반드시 존재해야 한다. 즉, 레이블 정보가 각 레코드마다 누락 없이 포함되어 있어야 한다. 분할 비율의 합 및 값 범위 조건은 기본 분할과 동일하다. 추가로, 각 레이블 당 최소 N개의 샘플 필요 조건이 있다: 데이터셋에 존재하는 각 레이블 클래스마다, 분할 세트 수 (학습/검증/테스트 중 사용되는 세트의 개수) 이상으로 샘플이 있어야 이상적으로 모든 세트에 그 레이블이 나타날 수 있다. 예를 들어 클래스 'X'의 샘플이 데이터 전체에 2개뿐인데 학습/테스트 (2-way) 분할을 한다면, 한 세트에 'X'가 나타나지 않을 수 있다. 이러한 경우 엄격히는 완전한 계층 분할이 불가능하며, 알고리즘은 가능한 한 분포를 맞추도록 시도하겠지만 일부 세트에는 해당 레이블이 빠질 수 있다. 레이블별 샘플 수가 너무 적은 경우 (특히 레이블 종류 수가 데이터 크기에 비해 많은 경우)에는 경고를 내거나, 필요에 따라 예외를 발생시킬 수 있다. 또한 레이블이 연속형 숫자 등 무한한 값으로 존재하는 경우 (예: 회귀 문제의 타깃 값)에는 계층적 분할이 정의되지 않으므로 이 기능은 범주형 클래스 분포에 대해서만 의미가 있다. 내부 처리 흐름 및 로직 요약:
입력 및 레이블 유효성 검증: dataset에서 label_field에 해당하는 레이블 정보를 추출한다. 레이블 데이터가 누락된 레코드가 있거나, label_field 자체가 잘못 지정된 경우 예외를 발생시킨다. 또한 전체 레이블의 고유 값 목록(클래스 목록)과 각 클래스별 샘플 개수를 집계한다. 이때 분할 대상 세트의 수 (예: 학습/검증/테스트 3개 세트를 모두 사용할 경우 3, 검증 생략 시 2)에 대해 각 클래스의 샘플 수를 확인하여, 만약 클래스 개수가 세트 수보다 작다면 경고를 기록한다. 분할 비율들도 #B7D12-F0001과 동일한 방식으로 유효성 체크를 수행한다 (합계 1 확인 등).
레이블별 그룹화: 데이터셋을 레이블 값별로 그룹으로 분류한다. 예를 들어 클래스 A, B, C가 있다면 각 클래스별로 해당 레코드 목록을 별도로 모은다. 이렇게 하면 각 그룹 내에는 동일 레이블의 레코드만 포함된다.
레이블 내부 셔플: shuffle=True인 경우 각 레이블 그룹 내에서 레코드 순서를 무작위로 섞는다 (random_seed가 지정된 경우 시드를 동일하게 적용하여 그룹별로 섞음). shuffle=False인 경우 원본 순서를 유지하지만, 일반적으로 계층적 분할에서도 그룹 내 섞기를 적용하여 분할 편향을 줄이는 것이 바람직하다.
클래스별 분할 할당량 계산: 각 레이블 그룹에 대해, 해당 그룹의 총 개수를 분할 비율에 맞게 나눌 개수를 계산한다. 예를 들어 어떤 클래스 X에 100개의 레코드가 있고 학습:검증:테스트 비율이 8:1:1이라면, 학습용으로 80개, 검증 10개, 테스트 10개를 그 그룹에서 뽑도록 목표를 정한다. 이 계산은 실수 결과일 경우 적절히 반올림하거나 내림하여 정수로 만든다. (예: 100개의 10% = 10개, 100개의 20% = 20개 등. 105개의 10% = 10.5개인 경우 10개 또는 11개로 반올림 처리.) 만약 이 연산 결과 어떤 클래스에서 특정 세트로 할당되는 개수가 0으로 산출되면, 해당 클래스는 그 세트에는 포함되지 않을 수 있다 (예: 클래스 Y 총 2개, 테스트 비율 10%라면 0.2개 → 0개로 계산되어 테스트 세트에는 Y가 없음). 알고리즘은 이러한 경우에도 모든 클래스의 분포 비율 차이가 최소화되도록 남은 분할에 그 클래스의 데이터를 포함시키는 방향으로 처리한다.
레코드 선택 및 합치기: 위에서 계산된 할당량을 기반으로 각 클래스 그룹에서 순서대로 레코드를 잘라내 각 세트에 배정한다. 예를 들어 클래스 A 그룹에서 앞의 80개를 학습 세트, 다음 10개를 검증 세트, 다음 10개를 테스트 세트로 보낸다. 클래스 B 그룹에서도 동일한 비율로 나누어 각 세트에 보낸다. 이 작업을 모든 클래스에 대해 수행한 후, 학습 세트는 각 클래스에서 할당된 학습용 레코드를 모두 합친 것이 되고, 검증 세트와 테스트 세트도 각각 해당 클래스별 할당분을 합쳐서 구성한다. 이때 각 세트에는 여러 클래스의 데이터가 섞여 있게 되지만, 클래스 비율은 원본과 거의 유사하게 맞춰져 있다. (필요시 최종적으로 각 세트별 레이블 분포를 확인하고, 혹시 큰 차이가 나는 경우 추가로 몇 개의 레코드를 세트 간 이동시켜 조정할 수도 있다.)
출력 생성: 최종적으로 완성된 학습/검증/테스트 세트를 반환한다. 반환 구조는 #B7D12-F0001과 동일하게 딕셔너리 등으로 구성하며, 각 키에 해당 세트의 데이터가 담긴다.
출력 데이터의 구조 및 설명:
출력 형식은 기본 분할 기능과 동일하다: "train", "validation", "test" 키를 가지는 구조체(예: 딕셔너리)를 반환하며, 각 키의 값은 그 세트에 해당하는 데이터셋이다. 각 세트의 데이터셋에는 원본과 동일한 필드 구조를 가진 레코드들이 들어있다. 특징: 각 세트 내의 레이블 분포가 원본과 거의 같도록 유지된 점이다. 예를 들어 원본 데이터셋의 클래스 분포가 A: 70%, B: 30%였다면, 학습 세트, 검증 세트, 테스트 세트 각각에서도 A 대 B 비율이 대략 7:3에 가깝게 유지된다. 모든 클래스가 각 세트에 반드시 포함되는 것은 아니지만 (아주 드문 클래스는 일부 세트에 없을 수 있음), 대부분의 경우 각 클래스의 상대적인 비율 차이가 최소화된다. 이러한 출력은 모델이 학습 세트에서 모든 클래스에 대한 충분한 표본을 학습하고, 검증/테스트 세트에서도 각 클래스별 성능을 평가할 수 있도록 도와준다. 발생 가능한 예외 또는 경고 조건:
레이블 필드 오류: label_field 파라미터가 데이터셋에 존재하지 않거나, 레이블 정보가 일부 레코드에서 누락된 경우 예외를 발생시킨다. 예를 들어 잘못된 컬럼명을 지정했거나 레이블 배열의 길이가 데이터셋과 맞지 않는 경우 "유효한 레이블 필드를 찾을 수 없습니다", "레이블 정보가 누락된 레코드가 있습니다" 등의 오류가 보고된다.
레이블 클래스 불균형 경고: 특정 레이블 클래스의 샘플 수가 매우 적어서 모든 세트에 분배할 수 없는 경우 경고를 남긴다. 예를 들어 데이터셋 전체에 한 클래스가 1개만 있다면, 그 클래스는 학습 또는 테스트 세트 중 한 곳에만 존재하게 되고 다른 세트에는 포함되지 않는다. 이때 "경고: 일부 클래스는 데이터가 부족하여 일부 분할 세트에 포함되지 않았습니다 (클래스=XYZ)" 등의 메시지를 통해 사용자에게 알려준다. 그래도 알고리즘은 가능한 한 해당 클래스를 학습 세트에 포함시켜 모델이 학습할 수 있도록 한다.
데이터셋 크기 및 비율 오류: 기본 분할과 마찬가지로, 분할 비율의 합이 1이 아니거나 값이 범위를 벗어나면 오류를 일으킨다. 또한 전체 데이터가 너무 작아서 클래스별로 할당할 때 0개가 발생하는 상황이 많다면, "데이터셋이 작아 계층적 분할 결과 일부 세트에 데이터가 거의 없습니다" 등의 경고를 할 수 있다.
기타: 계층적 분할을 사용하는 경우 shuffle=False 설정은 일반적으로 권장되지 않는다. 만약 사용자가 shuffle을 False로 지정하면, 클래스별로 원본 순서대로 분할하여 각 세트에 배정하므로 예기치 않은 순서 의존적 결과가 나올 수 있다. 예를 들어 원본 데이터가 클래스별로 정렬되어 있다면, shuffle=False 상태에서는 학습 세트에 특정 클래스만 몰리고 다른 세트에는 다른 클래스만 있는 현상이 발생할 수 있다. 따라서 이런 상황에서는 "경고: shuffle=False 설정으로 인해 레이블 분포가 왜곡될 수 있습니다. 가능한 shuffle=True로 설정하십시오." 같은 안내를 한다. 또한 레이블이 수치형 연속값인 경우 해당 분할 기능을 지원하지 않으며, 이때 **"오류: 연속형 값에 대해서는 계층적 분할을 적용할 수 없습니다"**를 반환할 수 있다.
예시 시나리오:
예를 들어, 1,000개의 샘플로 이루어진 데이터셋에 클래스 A와 B 두 종류의 레이블이 있다고 가정한다 (예: A 레이블 700개, B 레이블 300개로 원본 분포 7:3). 사용자가 학습:검증:테스트 비율을 8:1:1로 설정하고 이 계층적 분할 기능을 적용하면, 결과로 얻은 학습 세트, 검증 세트, 테스트 세트 모두에서 레이블 A 대 B의 비율이 약 7:3에 가깝게 유지된다. 구체적으로 학습 세트에는 A 레이블 약 560개, B 레이블 240개 (총 800개)가 포함되고, 검증 세트에는 A 레이블 70개, B 레이블 30개 (총 100개), 테스트 세트에도 A 레이블 70개, B 레이블 30개 (총 100개)가 들어간다. 이렇게 각 세트는 원본과 유사한 레이블 분포를 가지므로, 예를 들어 B와 같은 소수 클래스도 테스트 세트에 일정 수 포함되어 모델의 예측 성능을 검증할 수 있다. 만약 클래스가 더 많거나 분포가 불균형한 경우에도 이 기능은 같은 원리로 적용되며, 예컨대 5개 클래스가 있는 데이터셋을 8:2 (학습:테스트)로 나눌 때 각 클래스의 80%를 학습 세트에, 20%를 테스트 세트에 포함시키도록 시도한다. 이때 일부 극단적으로 적은 클래스(예: 전체 5개 미만 샘플)는 테스트 세트에 하나도 포함되지 않을 수 있지만, 이는 앞서 언급한 제한 사항에 따른 것이다. 그럼에도 대부분의 클래스는 각 세트에 고르게 나타나도록 분할된다.

3) #B7D12-F0003: K-폴드 교차 검증용 데이터 분할
기능 개요:
**K-폴드 교차 검증(K-fold cross validation)**을 위해 데이터셋을 K개의 폴드(fold)로 나누는 기능이다. 이 기능은 단일 학습-테스트 분할이 아니라, 모델 평가의 안정성을 높이기 위해 여러 번의 반복 학습/검증에 사용할 수 있도록 데이터를 K개의 부분집합으로 분할한다. 결과적으로 각 폴드는 한 번씩 검증(또는 테스트) 데이터셋의 역할을 맡고, 나머지 K-1개의 폴드는 해당 iteration에서 학습 데이터셋이 된다. 이 방식은 특히 데이터량이 적거나 모델의 일반화 성능을 더 엄밀히 평가하고자 할 때 유용하다. 본 기능은 K 값을 입력 받아 자동으로 폴드를 생성하며, 필요에 따라 무작위 섞기 및 시드 설정을 지원하여 각 폴드 구성이 임의성이 있으면서도 재현 가능하도록 한다. 입력 파라미터 및 유효성 조건:
dataset: 전체 데이터셋 (분할 대상). 레코드 수를 N이라고 할 때, N이 K보다 크거나 같아야 의미 있는 분할이 가능하다.
K (int): 생성할 폴드의 개수. 2 이상의 정수이어야 한다. 예를 들어 K=5로 지정하면 데이터셋을 거의 동일한 크기의 5개 부분으로 나눈다. K 값이 너무 크거나 (N < K인 경우) 1 이하인 경우 유효하지 않다.
shuffle (bool): 폴드 분할 전에 데이터를 섞을지 여부. 기본값 True로, 데이터를 무작위로 섞은 후 폴드를 만들면 각 폴드가 데이터 분포 면에서 보다 랜덤하고 균질해진다. False로 설정하면 원본 순서대로 폴드를 나누는데, 이는 데이터에 순서적 편향이 없을 때만 권장된다.
random_seed (int, 선택): 셔플을 적용할 경우 사용할 랜덤 시드. 동일한 시드와 K 값에 대해서는 항상 같은 폴드 구성이 나오므로, 결과 재현을 위해 시드를 지정할 수 있다.
유효성 조건: K는 2 이상이어야 하며, dataset 크기 N보다 클 수 없다. 만약 K=N이라면 각 폴드에 1개씩의 데이터가 들어가는 극단적 상황(Leave-One-Out CV)이 되는데, 이 경우도 동작은 가능하지만 K 값이 데이터셋 크기보다 훨씬 큰 경우 (예: N=50, K=50 등) 모델 학습 시 폴드당 데이터가 매우 적어져 과적합 위험이 높다는 점을 유념해야 한다. 일반적으로 K=5나 10 등의 값이 활용된다. K가 N보다 큰 값이 입력되면 **"오류: 데이터 개수보다 큰 K 값을 지정할 수 없습니다"**를 발생시킨다. 또한 dataset이 비어있거나 K=1인 경우도 분할 의미가 없으므로 예외 처리한다. shuffle과 random_seed의 유효성은 이전 기능들과 동일하게 논리적인 값(불리언, 정수 시드)인지 확인하며, 특별한 제한은 없다. 내부 처리 흐름 및 로직 요약:
입력 검증: dataset의 크기 N과 입력된 K 값을 확인한다. 위 유효성 조건에 따라 K가 2 이상이고 N >= K인지 검사하며, 조건에 맞지 않으면 즉시 예외 반환한다.
데이터 셔플: shuffle=True인 경우 random_seed를 사용하여 데이터셋을 무작위로 섞는다. 이 단계는 교차 검증 폴드가 편향 없이 고르게 섞이도록 하기 위함이다. shuffle=False이면 원본 순서를 유지한다.
폴드 분할: 섞인 데이터셋 (또는 원본 순서 데이터셋)을 연속된 K개 부분으로 나눈다. 분할은 가능한 한 동일한 크기로 이루어지며, N이 K로 나누어 떨어지지 않는 경우 일부 폴드는 한 개 정도의 추가 샘플을 가질 수 있다. 예를 들어 N=102이고 K=5라면, 이상적인 폴드 크기는 약 20.4이지만 정수로는 20개씩이고 몇 개 폴드는 21개를 가질 수 있다. 구현상으로는 보통 fold_size = floor(N/K)로 설정한 뒤, 처음 몇 개 폴드에 하나씩 추가 샘플을 배정하여 전체 N를 분배한다. 이렇게 하면 전체 K개 폴드의 크기 합이 N에 맞춰지고, 크기 차이가 최대 1로 균등하게 유지된다.
폴드 묶음 생성: 각 폴드를 순서대로 번호 매긴다 (예: 1번 폴드, 2번 폴드, ... K번 폴드). 이제 교차 검증용 학습/검증 세트를 만들기 위해, i번째 (1<=i<=K) iteration에서는 i번 폴드를 검증 세트로 사용하고, 나머지 K-1개 폴드를 모두 합쳐 학습 세트로 사용한다. 이 개념을 코드로 구현할 때는 모든 폴드의 인덱스 목록을 미리 만들어 두고, 각 i에 대해 train_indices = 전체 인덱스 - fold_i의 인덱스로 설정할 수 있다.
출력 구조 준비: 최종적으로 각 fold iteration에 대응하는 학습/검증 세트 쌍을 리스트나 반복 가능한 객체 형태로 구성한다. 예를 들어 길이가 K인 리스트 folds를 만들고, folds[i] = {"train": train_set_i, "validation": val_set_i} 로 저장한다. 여기서 val_set_i는 i번 폴드의 데이터이고, train_set_i는 나머지 모든 폴드 데이터의 합이다. 이렇게 하면 K번의 학습-검증 세트 쌍이 생성된다.
출력 데이터의 구조 및 설명:
이 기능은 여러 세트의 묶음을 반환한다. 일반적으로 리스트(배열) 형태로 K개의 원소를 갖으며, 각 원소는 하나의 fold에 대한 학습/검증 세트 정보를 담는다. 구조의 예시는 다음과 같다:
[
  {"train": Dataset객체_폴드1제외, "validation": Dataset객체_폴드1}, 
  {"train": Dataset객체_폴드2제외, "validation": Dataset객체_폴드2},
  ... 
  {"train": Dataset객체_폴드K제외, "validation": Dataset객체_폴드K}
]
여기서 Dataset객체_폴드X는 K개로 나눈 폴드 중 X번째 폴드의 데이터 부분이며, Dataset객체_폴드X제외는 전체 데이터셋에서 폴드 X의 데이터를 제외한 나머지(즉, 다른 폴드 모두 합친 것)이다. 각 train과 validation 세트는 원본 데이터와 같은 구조를 가지며, 분류 문제의 경우 레이블 분포가 원본과 비슷하게 섞여 있을 것으로 기대된다(무작위 셔플한 경우). folds 리스트의 길이는 K이고, 사용자 혹은 시스템은 이 리스트를 순회하면서 K번의 훈련-검증을 수행할 수 있다. 또한 모든 데이터 포인트는 한 번씩은 "validation" 세트에 속하게 되고, 나머지 시간에는 "train" 세트에 속하게 됨으로써, 각 데이터가 정확히 1번 검증에 사용되는 것이 보장된다. 발생 가능한 예외 또는 경고 조건:
K 값 오류: K가 2 미만이거나 정수가 아닌 경우 (예: K=1, K=0, K=2.5 등) 예외가 발생한다. **"K는 2 이상의 정수여야 합니다."**와 같은 오류 메시지가 반환된다.
데이터셋 크기 오류: N < K 인 경우 (예: 데이터 50개인데 K=100을 요청한 경우) **"데이터 레코드 수보다 폴드 개수가 많습니다."**라는 오류를 보고하고 분할을 중단한다.
빈 데이터셋 오류: dataset이 비어 있는 경우 분할할 수 없으므로 예외 처리한다 (기본 분할과 동일한 방식).
경고 - 소량 데이터: K는 유효하지만 데이터가 매우 적어서 폴드 크기가 너무 작을 경우, 결과는 얻어지더라도 신뢰도 문제가 있을 수 있다. 예를 들어 10개의 데이터로 K=5 교차검증을 하면 검증 세트는 2개, 학습 세트는 8개로 매우 적은 양으로 모델을 여러 번 돌리게 된다. 이런 상황에서는 "경고: 데이터셋 크기에 비해 K 값이 커서 각 폴드의 크기가 매우 작습니다. 교차 검증 결과의 변동이 클 수 있습니다." 등을 출력하여 사용자에게 알려줄 수 있다.
순서 관련 주의: shuffle=False로 폴드를 생성한 경우, 만약 원본 데이터에 특정 순서상의 구조가 있다면 (예: 정렬되어 있거나 시간 순서 등), 일부 폴드들이 편향될 수 있다. 예를 들어 레이블별로 정렬된 데이터에서 shuffle 없이 K-fold를 만들면, 첫 번째 폴드에는 특정 클래스만 들어갈 위험이 있다. 이 경우 "경고: shuffle을 비활성화하여 폴드를 생성했습니다. 데이터 순서에 패턴이 있는 경우 폴드 분포가 치우칠 수 있습니다." 등의 경고를 남긴다. 사용자가 명시적으로 False로 설정한 것이므로 예외는 아니지만 결과 해석에 주의를 촉구한다.
기타: K-fold 분할에서는 일반적인 분할과 달리 테스트 세트를 별도로 생성하지 않으므로, 이 기능 자체로는 최종 일반화 성능 평가용 테스트 데이터는 제공하지 않는다. 만약 사용자가 교차검증과 별도로 최종 테스트 세트를 보유하고 있다면, 그 부분은 데이터에서 미리 제외하고 교차검증을 수행해야 한다. 이러한 사용 팁을 문서화 차원에서 주석이나 가이드로 제공할 수 있다.
예시 시나리오:
예를 들어, 100개의 샘플로 이루어진 데이터셋에 대해 K=5로 지정하여 본 기능을 호출하면, 대략 각 폴드당 20개 정도의 데이터가 할당되어 총 5개의 폴드가 만들어진다. 함수는 이 100개 데이터를 무작위로 섞은 뒤 20개씩 5묶음으로 나누어 폴드를 생성한다 (만약 100이 정확히 나누어떨어지지 않는 경우 일부 폴드는 21개 또는 19개의 데이터를 가질 수 있지만, 여기서는 100이 5로 딱 나누어져 20개씩으로 가정). 출력 결과로 folds 리스트에는 5개의 원소가 있으며, 예컨대 folds[0]는 {"train": 80개 데이터, "validation": 20개 데이터} 형태다. 구체적으로 첫 번째 폴드(폴드1)를 검증 세트로 쓴 iteration의 경우 폴드1의 20개 데이터가 "validation"에, 나머지 25번 폴드의 80개 데이터가 "train"에 담긴다. 두 번째 iteration에서는 폴드2가 "validation" (20개), 나머지 폴드(1,3,4,5 합계 80개)가 "train"이 된다. 이런 식으로 다섯 번의 학습-검증 쌍이 마련되며, 사용자는 5번의 모델 학습과 평가를 진행한 후, 다섯 번의 평가 결과를 평균내어 최종 모델 성능을 추정할 수 있다. 이때 각 데이터 포인트는 한번씩 검증 과정에 사용되므로 데이터 효율을 최대한 높여 평가를 수행한 셈이다. 만약 shuffle=False였다면 원본 순서대로 120번째 레코드가 폴드1, 21~40번째가 폴드2 식으로 나누어졌을 것이고, 데이터가 어떤 규칙으로 정렬되어 있었다면 각 폴드에 치우친 패턴이 나타날 수 있다. 일반적인 사용에서는 shuffle=True로 설정하여 랜덤한 폴드를 생성하는 것을 권장한다.

4) #B7D12-F0004: 순차적(시계열) 데이터 분할
기능 개요:
시간 순서나 발생 순서를 고려하여 데이터를 분할하는 기능이다. 주로 시계열 데이터나 시간에 따라 변화하는 데이터셋에 사용된다. 이 기능은 데이터의 기존 순서를 유지하면서 앞부분의 데이터를 학습에 사용하고 뒷부분의 데이터를 검증/테스트에 사용하도록 분할한다. 임의로 데이터를 섞지 않기 때문에, 미래의 데이터로 과거를 예측하는 타임 시리즈 예측 모델링에 적합하다. 예컨대 주가나 기후 데이터처럼 시간에 따라 순차적으로 의존하는 데이터를 다룰 때는, 과거 데이터로 모델을 학습시키고 나서 실제 미래에 해당하는 기간의 데이터로 평가해야 하는데, 이 기능이 그런 순차 분할을 자동으로 수행해 준다. Amazon ML 등에서 제공하는 **순차적 분할(sequential split)**과 개념을 같이하며, 사용자가 지정한 시점 기준 또는 비율 기준으로 데이터셋을 앞뒤로 나눈다. 입력 파라미터 및 유효성 조건:
dataset: 시간 순으로 정렬된 전체 데이터셋. 만약 데이터가 시간 순으로 정렬되어 있지 않다면 time_column을 함께 제공하여 정렬 기준을 명시해야 한다.
time_column (선택): 데이터셋 내에서 시간 정보를 나타내는 칼럼 또는 속성. 예: 날짜/시간 스탬프가 들어있는 칼럼 이름. 제공되면 함수 내부에서 이 칼럼 값을 기준으로 데이터를 오래된 순→최근 순으로 정렬한 후 분할한다. 생략된 경우, 입력된 dataset이 이미 시간 순으로 정렬된 것으로 간주하고 주어진 순서를 그대로 사용한다.
train_fraction, validation_fraction, test_fraction: 시간 순으로 분할할 비율. 기본 분할 (#B7D12-F0001)과 동일하게 전체에서 차지하는 비율을 명시한다. 이들 값의 합은 1.0이어야 하며, 검증 세트를 사용하지 않을 경우 validation_fraction=0으로 설정할 수 있다. 보통 시계열 데이터의 경우 학습과 테스트만 사용하는 경우도 많지만, 필요에 따라 중간 검증 기간을 설정할 수 있다.
(shuffle): 이 기능에서는 shuffle 파라미터를 사용하지 않는 것을 권장한다. 순차적 분할은 의도적으로 시간 순서를 유지하는 기능이므로, 만약 shuffle=True로 주어져도 함수는 이를 무시하거나 강제로 False로 간주한다. 따라서 사용자 입장에서는 shuffle 옵션을 지정할 필요가 없다. (일부 구현에서는 이 파라미터를 지원하되 내부에서 강제 False 처리하고 경고를 줄 수 있다.)
유효성 조건: dataset 자체가 시간 순서를 따르고 있거나, time_column을 통해 시간 순 정렬이 가능해야 한다. time_column이 제공됐는데 데이터에 해당 칼럼이 없거나 시간 형식으로 해석 불가능한 값이면 예외를 일으킨다. 분할 비율들 (train/validation/test fraction) 합계는 1.0이어야 하며 범위 조건은 기본과 동일하다. 또한 분할하려는 세트 각각에 최소 하나 이상의 데이터가 있어야 한다는 조건도 적용된다. 특히 시계열 분할에서는 학습 세트가 너무 작거나 테스트 세트가 아예 없는 설정 (예: test_fraction=0) 등을 피해야 한다. 만약 test_fraction=0인 경우 시계열 예측을 평가할 데이터가 없으므로 일반적으로 test_fraction은 0이 아닌 값을 요구하며, validation_fraction는 선택적이다. 데이터셋이 아주 작아서 세 부분(또는 두 부분)으로 나누기 어려우면 오류 처리된다. 내부 처리 흐름 및 로직 요약:
입력 정렬 및 검증: time_column 파라미터가 지정된 경우, 데이터셋을 해당 칼럼 값 기준으로 오름차순 정렬한다. 이때 시간 데이터의 파싱이나 정렬이 제대로 되는지 확인하며, 문제가 있으면 예외 발생 (예: 시간 형식 오류). 만약 time_column이 없으면, 데이터셋은 이미 시간순으로 정렬된 것으로 가정한다. (필요하다면 내부 메타데이터로 체크할 수도 있지만, 주로 사용자가 올바른 순서로 제공한다고 본다.)
비율 계산: 정렬된 데이터셋에서 학습/검증/테스트에 할당할 비율만큼의 경계를 계산한다. 예를 들어 train_fraction=0.7, validation_fraction=0.2, test_fraction=0.1이라면, 학습 세트는 처음 70%, 검증 세트는 다음 20%, 테스트 세트는 마지막 10%로 정해진다. 이를 위한 인덱스 경계를 N을 기반으로 산출한다. 예를 들어 N=1000이라면 train_index_end = floor(0.7 * 1000) = 700, validation_index_end = 700 + floor(0.2 * 1000) = 700 + 200 = 900 등으로 결정한다. (floor 대신 정확한 비율에 따라 일부 잔여 데이터를 마지막 세트에 포함시키는 방식으로 구현 가능.)
순차적 분할 수행: 데이터를 앞에서부터 train_index_end까지 학습용 부분으로 취한다. 그 다음 train_index_end+1부터 validation_index_end까지를 검증용 부분으로 할당한다 (만약 validation_fraction=0이면 이 부분은 생략한다). 그리고 validation_index_end+1부터 끝까지를 테스트용 부분으로 취한다. 이러한 분할은 연속된 시계열 구간으로 이루어진다. 학습 세트는 가장 과거의 데이터, 테스트 세트는 가장 최근 데이터로 채워지며, (검증 세트가 있다면 학습과 테스트 사이의 기간 데이터로 구성된다.)
결과 출력 구성: 학습/검증/테스트 세트를 담은 구조를 생성하여 반환한다. 출력 형태는 기본 분할과 동일하게 {"train": ..., "validation": ..., "test": ...} 딕셔너리 등이 사용된다. 이때 shuffle은 적용되지 않았으므로, 각 세트 내부의 데이터 순서도 시간순이 보존되어 있다 (예: 학습 세트의 첫 레코드는 가장 오래된 시점, 테스트 세트의 마지막 레코드는 가장 최신 시점 데이터).
출력 데이터의 구조 및 설명:
출력은 "train", "validation", "test" 키를 갖는 사전 구조로, 각 부분에 해당하는 데이터셋 조각을 담는다. 각 세트의 레코드들은 원본 데이터셋과 동일한 구조를 가지며, 중요한 점은 시간 순서가 보존되어 있다는 것이다. 예를 들어 학습 세트의 마지막 레코드는 검증 세트의 첫 레코드보다 시간적으로 이전 시점의 데이터이고, 검증 세트의 마지막 레코드는 테스트 세트의 첫 레코드보다 이전 시점이다. 이렇게 시간 축을 따라 연속성이 유지되므로, 학습->검증->테스트 순으로 시간이 흐른다고 볼 수 있다. 학습 세트는 과거 데이터로 구성되고, 테스트 세트는 가장 미래(또는 최신) 데이터로 구성된다. 각 세트에 포함된 레코드 수는 입력된 fraction 비율에 근거하며, 예를 들어 70:20:10 분할의 경우 대략 70%의 오래된 데이터는 학습, 20% 중간 시점 데이터는 검증, 10% 최근 데이터는 테스트 세트에 위치한다. 모델은 학습 세트로 훈련되고, 시간적으로 이후의 데이터들로 성능을 검증/평가받게 되므로 **정보 누설(leakage)**이 없도록 보장된다. 출력 구조는 모델 훈련 파이프라인에서 시계열 데이터를 다룰 때 바로 사용할 수 있도록 설계된다. 발생 가능한 예외 또는 경고 조건:
시간 칼럼 오류: time_column이 제공되었으나 데이터셋에 해당 칼럼이 없거나, 시간값이 유효하지 않은 형식이면 예외를 발생시킨다. 메시지 예: "지정된 시간 칼럼 'event_time'을 찾을 수 없거나 시간 형식이 잘못되었습니다."
분할 비율 합계 오류: train/validation/test fraction의 합이 1.0이 아닌 경우 오류 처리 (기본 분할과 동일).
데이터 크기 부족 오류: 데이터셋이 너무 작아서 주어진 비율대로 2개 또는 3개의 부분으로 나눌 수 없을 때 예외를 발생시킨다. 예를 들어 3개의 레코드만 있는 시계열 데이터에 train_fraction=0.7, validation_fraction=0.2, test_fraction=0.1로 요청하면, 각각 2.1,0.6,0.3개로 계산되어 일부 세트는 0개가 될 수밖에 없으므로 "데이터가 부족하여 시계열 분할을 수행할 수 없습니다" 등의 오류가 발생한다.
0% 테스트 경고: 시계열 분할에서 test_fraction=0으로 설정한 경우, 미래 데이터에 대한 평가 세트가 없으므로 이런 설정은 일반적으로 잘못된 구성이다. 함수는 이 경우 전체 데이터를 학습(+검증) 세트로만 나누고 테스트 세트는 비워두겠지만, "경고: 테스트 세트 비율이 0으로 설정되어 있습니다. 시계열 예측 모델의 성능을 평가할 테스트 데이터가 존재하지 않습니다." 같은 안내를 할 수 있다.
셔플 무시 경고: 사용자가 혹여 shuffle=True를 지정하여 호출했더라도, 함수는 이를 무시하고 순차 분할을 수행한다. 이때 "알림: 시계열 분할에서는 shuffle 옵션이 적용되지 않으므로 순서가 유지됩니다." 등의 로그나 경고를 남겨, 무작위 분할이 일어나지 않았음을 분명히 한다.
시간 중복/역순 데이터 경고: 만약 데이터셋에 동일한 타임스탬프를 가진 레코드가 많거나 시간 순서가 역전된 부분이 있으면, 분할 결과가 모호할 수 있다. 일반적으로 시간 중복은 괜찮지만, 시간 순 정렬 시 임의의 기준으로 정렬될 수 있음을 알린다. 예: "경고: 일부 레코드의 시간값이 동일합니다. 순차 분할 시 임의의 순서로 처리되었습니다." 또는 "경고: 데이터셋 내 시간 순서가 정렬되어 있지 않아 정렬 후 분할했습니다."
기타: 시계열 분할은 과거->미래의 순으로만 데이터를 나누므로, 학습 세트의 시점이 항상 검증/테스트 세트보다 이전이어야 한다. 만약 잘못된 파라미터로 인해 (예: train_fraction 너무 작게 설정) 학습 세트 시점이 매우 짧거나 나중 세트 시점과 겹치는 문제가 생기면, 잘못된 설정임을 경고하거나 비율 조정을 유도할 수 있다.
예시 시나리오:
예를 들어, 365일간의 일별 시계열 데이터(예: 2024년 1월 1일부터 12월 31일까지의 데이터)가 있다고 하자. 이 데이터를 7:2:1의 비율로 순차 분할하면, 대략 **처음 70% (약 255일치)**의 데이터를 학습 세트로 사용하고, **다음 20% (약 73일치)**를 검증 세트, **마지막 10% (약 37일치)**를 테스트 세트로 사용하게 된다. 학습 세트에는 1월 초부터 가을 무렵까지의 기록이, 검증 세트에는 그 이후 몇 달 치 기록이, 테스트 세트에는 가장 최근인 12월 초부터 12월 말까지의 기록이 포함되는 식이다. 이렇게 하면 모델은 1월~가을까지의 데이터로 학습하고, **가을~초겨울 데이터로 튜닝(검증)**하며, 연말의 데이터로 최종 성능 검증을 받는다. 시간 순서가 엄격히 지켜지므로, 모델 평가 시 미래 데이터(연말 데이터)를 전혀 학습에 사용하지 않았다는 것이 보장된다. 만약 사용자가 검증 세트를 사용하지 않고 학습/테스트만 나누려 한다면, 예를 들어 train_fraction=0.8, test_fraction=0.2, validation_fraction=0으로 설정하여 처음 80%를 학습, 마지막 20%를 테스트로 분할할 수 있다. 예컨대 365일 중 첫 292일을 학습, 마지막 73일을 테스트로 삼는 형태다. 이러한 시계열 분할 기능은 주가 예측 예시에서, 과거 몇 년간의 가격으로 학습한 모델을 최근 몇 달의 데이터를 가지고 평가하는 시나리오 등에 적용될 수 있다.

5) #B7D12-F0005: 그룹 기반 데이터 분할 (ID별 분리)
기능 개요:
데이터 내의 특정 그룹/식별자(ID) 단위를 기준으로 묶어서 분할하는 기능이다. 이 기능은 동일한 그룹에 속하는 데이터 레코드들이 학습용과 테스트용 등에 동시에 섞이지 않도록 보장한다. 예를 들어, 의료 데이터에서 동일 환자(patient ID)에 대한 기록들이 있다면, 한 환자의 데이터는 모두 학습 세트에 넣고 테스트 세트에는 그 환자의 데이터가 아예 없게 분리할 수 있다. 이렇게 하면 그룹 간 독립성을 확보하여, 그룹에 특화된 패턴이 모델 평가에 누출(leakage)되는 것을 막는다. 일반적인 용도로는 사용자별 로그 데이터, 제품별 판매 데이터 등 ID별로 다수 레코드가 존재하는 데이터셋에서, ID가 다른 데이터끼리만 학습/평가에 각각 쓰이도록 분리하고 싶을 때 사용된다. 입력 파라미터 및 유효성 조건:
dataset: 전체 데이터셋 (분할 대상). 여기에는 하나 이상의 그룹 식별자가 포함된 레코드들이 있다.
group_field: 그룹을 식별할 수 있는 키 또는 칼럼. 각 레코드는 이 필드를 통해 어떤 그룹에 속하는지 결정된다. 예를 들어 group_field="user_id"이면 동일한 user_id 값을 가진 레코드들은 한 그룹으로 간주된다. 그룹 식별자는 레코드 간 관계를 나타내며, 문자열, 숫자 등 식별 가능한 값이면 무엇이든 될 수 있다.
train_fraction, validation_fraction, test_fraction: 분할 비율. 의미와 제약 조건은 기본 분할과 유사하지만, 여기서는 비율이 데이터 건수 기준이 아니라 그룹 단위로 적용된다는 점이 특징이다. 정확히는 그룹별 레코드 수가 다를 수 있으므로, 엄밀히 비율을 맞추기보다는 전체 데이터 레코드 수 대비 대략적인 비율을 목표로 그룹들을 나누게 된다.
shuffle_groups (bool, 선택): 그룹을 분할하기 전에 그룹들의 순서를 무작위로 섞을지 여부. 기본값은 True로, 설정 시 그룹 배정을 랜덤하게 하여 치우침을 줄인다. False면 그룹 목록의 원본 순서(또는 정렬 순서)에 따라 분할하는데, 특별한 이유가 없다면 True가 권장된다. (shuffle_groups는 그룹 단위 섞기를 의미하며, 개별 레코드 섞기는 분할 결과에 영향을 주지 않는다.)
random_seed (int, 선택): 그룹을 섞을 때 사용할 시드 값. 지정하면 그룹 무작위 선택 순서를 재현 가능하게 한다.
유효성 조건: group_field는 반드시 데이터셋에 존재해야 하고, 모든 레코드가 어떤 그룹에 소속되어 있어야 한다. 그룹 식별값이 없는 레코드가 있으면 오류 처리된다. 고유 그룹의 개수를 G라고 할 때, G는 분할하려는 세트의 수 (예: 학습/검증/테스트 3세트라면 3, 검증 미사용 2세트라면 2) 이상이어야 한다. 만약 고유 그룹이 1개뿐인데 두 개 세트로 나누라고 하면, 한 세트는 그 그룹의 모든 데이터, 다른 세트는 아무 데이터도 없는 모순 상황이 되므로 불가능하다. 즉, G < 필요한 세트 수이면 예외가 발생한다. 또한 각 그룹의 크기(레코드 수)는 제각기 다를 수 있으므로, 목표 비율을 정확히 맞추기는 어렵다. 이 때문에 분할 로직은 비율에 최대한 근접하도록 그룹을 배정하지만, 엄밀하게 비율 합계 1.0 충족은 그룹 단위 분할에서는 보장되지 않을 수도 있다. (예: 10개 그룹 중 7개 그룹 데이터를 학습에 쓰면 학습 데이터 비율이 정확히 0.7일지라도, 그룹별 레코드 수 차이로 인해 실제 레코드 수 비율은 약간 다를 수 있음). 다만, 전체적인 레코드 수 관점에서 분할 비율에 가깝도록 그룹을 나눌 것이다.
또한 그룹 단위로 분할하면 특정 그룹이 매우 커서 하나의 그룹만으로도 전체 데이터의 대부분을 차지할 수 있다. 그런 경우 이상적인 비율과 크게 차이가 날 수 있다. 이러한 시나리오에서는 경고를 줄 수 있지만, 기능 자체는 여전히 수행된다 (필요하다면 사용자가 해당 큰 그룹을 따로 처리해야 함). 내부 처리 흐름 및 로직 요약:
입력 검증 및 그룹화: 주어진 dataset에서 group_field 값을 추출하여 고유한 그룹 리스트를 만든다. 각 레코드를 해당 group ID로 매핑하여 그룹별로 레코드 목록(또는 개수)를 파악한다. 그룹 리스트의 크기 G와 분할 세트 수를 비교하여, G가 세트 수보다 작으면 예외를 발생시킨다.
그룹 순서 섞기: shuffle_groups=True인 경우, 그룹 리스트를 random_seed를 사용하여 무작위로 셔플한다. 이는 그룹을 랜덤한 순서로 나열하여 이후 배정 시 치우침을 줄이기 위함이다. (예: 데이터가 이미 정렬되어 있을 때 발생할 수 있는 편향 감소)
그룹 분할 할당: 섞인 그룹 리스트를 순차적으로 훑으면서 각 그룹을 어느 세트에 넣을지 결정한다. 일반적인 방법은 비례 누적 할당이다: 우선 학습 세트에 그룹을 계속 추가해 나가다가, 학습 세트에 속한 전체 레코드 수가 목표인 train_fraction * N에 최대한 근접하면 학습 세트 할당을 멈춘다. 그 시점부터 이후의 그룹들은 검증 세트에 추가해 나가고, 검증 세트의 누적 레코드 수가 validation_fraction * N에 근접하면 검증 할당을 마친다. 나머지 그룹들은 테스트 세트로 넣는다. 이러한 방식으로 각 그룹 전체가 하나의 세트에 통째로 들어가도록 배정한다. (만약 validation_fraction=0인 경우는 바로 학습에서 테스트로 넘어가고, test_fraction=0이면 학습과 검증까지만 할당한다.)
경우에 따라, 그룹 크기 편차로 인해 이상적으로 의도한 비율보다 학습 세트에 조금 과소/과다 할당될 수 있다. 예를 들어 목표 학습 레코드수가 800개인데 그룹을 하나 더 넣으면 850개가 되어 80%를 넘을 수 있다. 이때 마지막 그룹을 포함할지 말지 결정해야 하는데, 일반적으로 학습 세트에는 목표보다 약간 넘게 할당하고, 그 대신 검증+테스트 세트에서 약간 부족해지는 식으로 처리할 수 있다. 또는 반대로 학습 세트가 약간 모자라게 두고 목표를 조금 희생할 수도 있다. 구현 방침에 따라 다르지만, 여기서는 가능한 모든 데이터를 활용하기 위해 큰 그룹은 포함시키는 것으로 가정한다.
만약 그룹 수가 많고 각 그룹이 작은 경우에는 거의 정확히 비율을 맞출 수 있다. 반대로 그룹 하나가 매우 큰 경우, 그 그룹을 어느 세트에 넣느냐에 따라 비율 차이가 크게 날 수 있다. 그런 경우 알고리즘은 한번에 그 큰 그룹을 통째로 배정할 수밖에 없으므로 결과 비율 차이는 감수한다.
데이터셋 구성: 그룹 할당이 끝나면, 학습 세트에 배정된 모든 그룹의 레코드를 모아 학습용 데이터셋을 만든다. 검증 세트 그룹들의 레코드를 모아 검증용 데이터셋을, 테스트 세트 그룹들의 레코드를 모아 테스트용 데이터셋을 각각 생성한다. 이 과정에서 각 세트에 포함된 레코드 수와 그룹 수 등을 계산하여 요약 정보를 얻을 수도 있다.
출력 반환: 완성된 학습/검증/테스트 세트를 반환한다.
출력 데이터의 구조 및 설명:
반환 구조는 기본 분할과 동일하게 {"train": ..., "validation": ..., "test": ...} 형태로 각 세트의 데이터를 담는다. 중요한 특성: 각 세트에는 동일한 group_field 값을 가진 레코드가 오직 하나의 세트에만 존재한다. 즉, 어떤 그룹 ID에 속하는 모든 데이터는 train이면 train에 모두 있고, validation이나 test에는 그 ID가 아예 없다. 이로써 학습과 평가 단계에서 그룹 간 격리가 유지된다. 예를 들어 user_id를 기준으로 분할했다면, 학습 세트의 user_id 목록과 테스트 세트의 user_id 목록이 공통 원소를 가지지 않는다.
각 세트의 데이터 구조(칼럼 등)는 원본과 동일하며, 레코드 수는 지정한 비율에 가깝게 할당된다. 다만 앞서 언급한 대로 그룹 크기 차이로 인해 완전히 정확한 비율은 아니고 약간 차이가 있을 수 있다. 예를 들어 100명의 사용자(user_id 100개)에 대한 1000건의 로그 데이터가 있는데, 이들을 8:2 (학습:테스트)로 그룹 분할했다면, 이론상 레코드 수 기준 800건 vs 200건을 목표로 한다. 실제 결과는 80명의 사용자의 데이터(예: 810건)가 학습 세트에, 나머지 20명 사용자 데이터(190건)가 테스트 세트에 들어갈 수 있다. 이 경우 학습 세트는 81%의 데이터, 테스트 세트는 19%의 데이터가 되었지만, 그룹 단위로 나눈 데 따른 자연스러운 오차이다. 이러한 출력은 그룹 별로 데이터가 완전히 분리되어 있으므로, 예컨대 테스트 세트에 등장한 사용자에 대한 데이터는 학습 세트에 전혀 없어 모델이 처음 보는 그룹에 대해 평가를 받게 된다. 이는 모델 일반화 평가 시 데이터 누설을 막고 보다 엄격한 평가를 가능하게 한다. 발생 가능한 예외 또는 경고 조건:
그룹 필드 오류: 지정된 group_field가 데이터셋에 존재하지 않거나 일부 레코드에서 해당 값이 누락되었을 경우 예외를 일으킨다. 메시지 예: "그룹 필드 'patient_id'를 찾을 수 없거나 일부 레코드에 값이 없습니다."
그룹 개수 부족 오류: 고유 그룹 수 G가 요구되는 세트 수보다 적은 경우 분할을 수행할 수 없다. 예를 들어 그룹이 2개뿐인데 train/val/test 3-way 분할을 시도하면 불가능하므로 **"그룹 개수가 분할 세트보다 적어 그룹 기반 분할을 수행할 수 없습니다."**라는 오류를 반환한다.
과도한 그룹 크기 경고: 특정 그룹이 전체 데이터의 상당 부분을 차지하는 경우, 원하는 비율에서 큰 오차가 발생할 수 있다. 예를 들어 전체 데이터 1000건 중 한 그룹이 500건을 가지고 있는데 8:1:1 분할하려 하면, 그 한 그룹을 학습 세트에 넣으면 이미 50%를 차지하여 학습 세트가 목표인 80%보다 훨씬 작아지고, 반대로 테스트나 검증에 넣으면 너무 커질 수 있다. 이런 경우 어느 쪽에 넣든 간에 불균형이 생기는데, 함수는 일단 임의의 한 세트에 넣되 "경고: 일부 그룹(user_id=XYZ)의 데이터 규모가 커서 분할 비율에 오차가 발생했습니다." 등을 남길 수 있다. 이는 사용자가 해당 그룹을 별도 처리하거나 분할 비율을 조정하는 것을 고려하도록 안내하는 것이다.
비율 엄격도 경고: 그룹 분할에서는 목표 분할 비율을 정확히 맞추기 어려우므로, 결과에서 비율이 조금 다르더라도 동작상 오류는 아니다. 그러나 혹시 사용자가 정확한 분할을 기대할 수 있으므로, "알림: 그룹별 분할 특성상 실제 레코드 수 비율은 지정한 비율과 약간 다를 수 있습니다." 등의 메시지를 제공할 수 있다.
기타: shuffle_groups를 False로 설정한 경우, 그룹 리스트의 원본 순서대로 분할을 하면 특정 패턴에 따라 분할 결과가 치우칠 수 있다. 예컨데 group_field 값이 정렬되어 있으면 (예: 작은 ID는 특정 특성을 가진 그룹들), 학습 세트에 작은 ID 그룹만 몰리고 큰 ID는 전부 테스트에 몰릴 수 있다. 이러한 비합리적 분할을 막기 위해 기본은 shuffle_groups=True이며, 만약 False가 선택되었다면 **"경고: shuffle_groups=False로 그룹을 분할합니다. 원본 그룹 순서에 패턴이 있을 경우 결과 분포가 왜곡될 수 있습니다."**를 경고한다.
예시 시나리오:
예를 들어, **100명의 사용자(user_id)**로부터 수집된 1000개의 데이터 레코드가 있다고 가정하자. 각 사용자는 평균 10개의 레코드를 가지고 있지만 편차가 있어서, 어떤 사용자는 30개, 어떤 사용자는 5개의 레코드를 가질 수도 있다. 이 데이터셋을 **8:2 비율 (학습:테스트)**로 그룹 기반 분할하게 되면, 약 80명의 사용자에 속한 모든 레코드들이 학습 세트로, 20명의 사용자의 모든 레코드들이 테스트 세트로 할당될 것이다. 예를 들어 user_id 1,2,...,80번 사용자의 모든 로그 데이터(총 합계가 약 800건)가 학습 세트에 들어가고, user_id 81~100번 사용자의 로그 데이터(약 200건)가 테스트 세트에 포함되는 식이다. 이때 테스트 세트에는 학습 세트와 겹치는 사용자가 한 명도 없으므로, 모델은 전혀 보지 못한 사용자들의 데이터로 테스트되는 셈이다. 이는 만약 사용자별로 데이터 패턴이 크게 다르면, 겹치지 않게 평가함으로써 모델의 일반화 능력을 더욱 엄격히 측정한다. 검증 세트를 추가로 사용하고 싶다면, 예를 들어 70% 학습, 15% 검증, 15% 테스트로 그룹 분할할 수 있다. 그러면 약 70명의 사용자 데이터는 학습, 15명은 검증, 15명은 테스트로 나뉘게 된다. 실제로는 100명의 70%인 70명, 15명, 15명으로 그룹 수 기준 정확히 떨어질 수 있지만, 레코드 수 기준으로는 예컨대 학습 710건, 검증 150건, 테스트 140건 식으로 조금 차이가 날 수 있다. 이러한 결과로도 각각 세트 간 그룹이 겹치지 않는 이점은 동일하며, 각 세트의 총 레코드 수도 원하는 범위 내에 들어오게 된다. 사용자는 이렇게 분할된 학습 세트를 모델 훈련에 사용하고, 검증 세트로 하이퍼파라미터 튜닝을 한 뒤, 마지막으로 **학습 때 한 번도 본 적 없는 새로운 그룹들(테스트 세트)**로 최종 평가를 수행하게 된다.
